DATE AND TIME: October 31, 2017 10:15am SESSION TITLE: Session 11, SecurityTALK TITLE: WatchIT: Who watches your IT Guy? SPEAKER: Noam ShalevKEYPOINTS:1. INTRODUCTION:61 Problem Statement/Motivation:C Companies’ data are handled by their IT departments (which may be handled by third parties)C These data may be confidential (e.g. data of banks)C IT support sees these confidential data and system administrators have full accessto them.C If even one of the employees/system admins is malicious he can easily steal thesedata.C Goal: build a system that prohibits malicious employees from stealing the dataand, at the same time, permits the honest IT employees to do their job61 Proposed Solution: WatchIT, a strategy to constrain the IT personnel’s and monitor their actions.61 Evaluation: Case study on IT department of IBM research 2. DETAILS61 Assumptions/Threat model:(a) System Admins don’t have access to the machines except if they need to serve a ticket/IT request.(b) TCB (Trusted Computing Base), i.e. only employees can be malicious. Not the software61 1st Idea to solve the problem:C Use containers to restrict each employee’s view of the system/data.C Advantages: lightweight, isolation/compartmentalization (i.e. Malicious IT em-ployee has access only to the resources that he needs to serve the ticket but notto the fill database)C Problem: What if an honest employee needs access to a resource outside thecontainer to perform the job he is assigned?61 Proposed solution to the above problem: Perforated containers which can punch the aforementioned isolation.61 Each container has its own view of the filesystem and of the processes that run in the machine.61 How does it work in high level? For each IT ticket, we need to predict the level of isolation needed to serve it and create the corresponding perforated container. Then, the user logins to the container and serves the ticket.61 Problem with the solution so far: If an IT employee accesses resources outside the container he can steal data61 Solution: ContainIT, a system that monitors users when they exit a container (sand- box).1
61 What we need to monitor:(a) Network (there were existing solutions to that)(b) Filesystem Operations: Build a new FUSE filesystem. The container shares thefilesystem with the host but it does not access anything it is not supposed to access.61 If the prediction for the isolation is wrong and the admin needs more access, it has to contact the Permission Broker which gives him access outside the container but monitors his actions3. EVALUATION:61 Case study in the IT department of IBM.61 Goal: Show that effective isolation is feasible.61 Method:(a) Analyze previous reported tickets and use machine learning techniques(LDA) to cluster them according to their description.(b) Custom Tailoring: What is the view that corresponds to each cluster (what resources it needs to have access to)(c) Test61 The study in IBM showed that for 62% of the tickets served, employees did not need to use the permission broker (i.e. they were able to accurately predict the level of isolation for majority of tickets).61 In 62% of the cases the system denied full system view61 It isolated the network view in 98% of the casesQ&A:1. Q1: What happens if you cannot start the container because of crashes? Wouldn’t that cause problems to the system?A1: There was only one such case in the case study2. Q2: I could not listen/understand the question. I think it had to do with the fact that the system classifies the requests according to their description and this description may be inaccurate.A2: The classifier was able to handle the tickets and classify them pretty well (so in most cases ticket’s description will be accurate). It is true that no machine can perfectly replace a human being.3. Q3: You assume that an adversary’s attack is associated to a single ticket. But, a malicious adversary may split his attack in many tickets i.e. use one ticket to get access to a subset of the resources that he needs to perform the attack and then use another ticket to gain access to the rest of the resources he needs.A3: Indeed, this is a true attack. Generally, a user may collide with the IT to fake tickets and get permissions4. Q4: If you were a malicious attack how would you attack your system? A4: As described in the previous answer2
DATE AND TIME: October 31, 2017 10:40am SESSION TITLE: Session 11, SecurityTALK TITLE: Secure Page Fusion with VUsion SPEAKER: Marco OliverioKEYPOINTS:1. INTRODUCTION:61 Fusion (also known with other names such as memory deduplication): if two pages are the same, merge them.61 Advantage: saves memory. Crucial for VMs: if we have 16 VMs, using fusion saves 60% space vs not using fusion.61 Problem: it is not secure because when two pages are merged they become write protected. This means that if an application tries to write a page that is merged, a copy-on-write event will be triggered and thus it will take more time for the write to be completed vs writing to an unmerged page. Thus, an adversary can measure the time it takes him to write pages to check if these pages exist (retrieve passwords of other users who use a VM in the same machine)61 Proposed solution: VUsion, secure page fusion system 2. DETAILS:61 Initial idea: Enforce the same behavior by making all pages write protected (merged and unmerged) i.e. fake merging.61 Problem with this idea: New attack: page color attack i.e. take advantage of how physical memory is mapped to cache sets and try to find merged pages by checking if the page has changed cache. This means that you can leak info by just accessing pages61 Solution: Remove all permissions from all pages.61 Consideration: Since there are many page faults now, the system may become slower.However, this turns out to be non-true because:(a) Page fusion scan is already very slow and is ran as a background process. (b) Most memory that is fused is idle.61 Another consideration: Memory massage attacks such as Rowhammer attack. Page fusion use of physical memory is predictable so it is easy for an adversary to identify ”good” positions in the memory to perform the attack and corrupt pages of other users.61 Solution: Randomized allocation i.e. add entropy to the process of physical memory allocation.3. IMPLEMENTATION/EVALUATION:61 Implementation on top of linux kernel, working set estimation, THP enhanced version61 Fuse rates(16 VMs): Measure memory consumption vs time: KSM reduces memory consumption by 60%, VUsion does the same in the long run61 Performance: Measure overhead (%) per benchmark (how much slower is the VM due to page faults): in many benchmarks no difference in performance vs KSM. For some benchmarks, performance is much worse vs KSM because these benchmarks are more sensible to page faults.3
61 Server throughput experiments: same as KSM (little lower)61 Server’s Latency: in the worst case 1ms slower than KSM.61 Experiments show that you cannot distinguish between merged and unmerged pages by the time it takes to access them.Q&As:1. Q1/A1: -2. Q2: Is it possible that VUsion has vulnerabilities that may be found in the future?A2: We have not formally proved that our system is secure but we have tried our best to make it impossible to distinguish between merged and unmerged pages.3. Q3: What percentage of the merged pages are the zero pages?A3: Not much. I would guess that if you only merged 0 pages you would get about 20% reduction in memory consumption.4. Q4: Why is latency for all systems so large?A4: We used a 1GB network multiplexed between VMs. Previous work has done the same.4
DATE AND TIME: October 31, 2017 11:05 am SESSION TITLE: Session 11, SecurityTALK TITLE: The efficient server audit problem SPEAKER: Marco OliverioKEYPOINTS:1. INTRODUCTION:61 Principal deploys a program to powerful but untrusted executor(server)61 Clients issue requests(inputs) to the server and get back responses(outputs)61 The server may serve these requests concurrently61 A verifier wants to audit the server to check that it executes the requests honestly i.e. that the purported outputs correspond to honest executions of the program on the inputs.61 A collector records the order/trace of requests/responses61 Server maintains reports whose purpose is to assist the audit.61 Problem Description/Desiredata:(a) Server is untrusted (b) Server is concurrent(c) Verifier is weaker than server (d) Server overhead is low61 Combination of the above is a new problem/setup61 Execution integrity is complementary to program verification2. DETAILS:61 Naive solution: Verifier just re-executes. Problem: Verifier does not save any work61 We need to accelerate the execution of the verifier and at the same time be able to efficiently and correctly handle shared objects between requests (i.e. key value stores or databases). There is a tension between these two.61 Poirot’ s observation: the requests on a server usually have the same control flow. (however Poirot’s setup is not exactly the same because Poirot trusts the advice).61 Accelerate re-execution without trusting the server:C Server sends a tag for each request. Requests with the same tag supposedly have the same control flowC Server groups the requests according to their tags and executes each group (out of order execution) using a new technique: SIMD on demandC SIMD on demand executes identical instructions (i.e. same operands) only once. If not same operands, ”multi-values” and, in the future, if all values become the same collapse in one scalar.C If two requests don’t share the same control flow it will be revealed during re- execution.C SIMD on demand eliminates redundant computations61 Out of order execution causes the following problem: how do we handle shared objects i.e. when we are re-executing out of order how can we check that the operations on the shared objects are done correctly?5
61 Attempt 1: Server logs reads, verifier supplies from log. Problem: Prover can log whatever he wants, no guarantee that writes indeed occurred61 Attempt 2: Server logs writes, verifier supplies from last write in the log. Problem: The server can claim that a write happened after the request has left the server or before the request has arrived to the server61 Intuition for solution: Prover logs reads, writes and requests/responses. Verifier must check that events are consistent with each other and with the trace he has from collector.3. EVALUATION: OROCHI61 Apps is PHP61 Goals: 1) Understand price for Verifiability 2) Verify that there are indeed many deduplication opportunities in real apps.61 Baseline: Simple re-execution because there is no other comprehensive way of achiev- ing this systems goals61 Experiments(MediaWiki) show that indeed many applications have a lot of identical instructions61 Orochi’s verifier is 5.6-10.9x more efficient than naive re-execution61 Verifies should store locally the DB.61 Prover’s overhead from collecting reports is less than 10%61 Orochi requires modest application adjustments61 Related work: None of existing works has the same setup and achieves the same goalsQ&As:1. Q1: How do you handle non-determinism such as PHP-builtins (time)?A1: The formal proof does not cover it but implementation handles them by having the server send the outputs of these calls as advice to the server. Then the server makes simple consistency tests (e.g. for time, check that for every two calls that happened the one after this is reflected at the timestamps they returned)2. Q2: What did you change in the code of the applications?A2: 1) Orochi has constraints when handing DBs: it cannot handle nested transactions. 2) Unfinished implementations3. Q3: Could you apply these techniques in other services?A3: We can easily adapt our techniques in high-level languages like Ruby or Python because the control flows are similar. For languages like Go it may be more difficult.6